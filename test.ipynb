{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\n",
    "\n",
    "abbc = requests.post(f\"http://127.0.0.1:1337/infer/ner\", json={\"text\": \"РАНХиГС\"})\n",
    "abbc.text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[{\"entity_group\":\"ORGANIZATION\",\"score\":0.9994713664054871,\"word\":\"РАНХиГС\",\"start\":0,\"end\":7}]'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "abbc = requests.post(f\"http://127.0.0.1:1337/infer/clf\", json={\"text\": \"кожа животных и коров\"})\n",
    "abbc.text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[{\"text\":\"кожа животных и коров\",\"class\":\"15\",\"score\":1.0}]'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import requests\n",
    "\n",
    "abbc = requests.post(f\"http://127.0.0.1:1337/infer/ner\", json={\"text\": \"в МГУ поступили 100 человек\"})\n",
    "abbc.text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[{\"entity_group\":\"ORGANIZATION\",\"score\":0.9993856549263,\"word\":\"МГУ\",\"start\":2,\"end\":5},{\"entity_group\":\"QUANTITY\",\"score\":0.6999955773353577,\"word\":\"100 человек\",\"start\":16,\"end\":27}]'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "uvicorn flask_server:app --reload --host 127.0.0.1 --port 1337"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-1a0c9652f86c>, line 1)",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-46-1a0c9652f86c>\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    uvicorn flask_server:app --reload --host 127.0.0.1 --port 1337\u001B[0m\n\u001B[1;37m            ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "path_ = r'..\\OKPD2\\tiny_bert_087_ner_rured_plus'\n",
    "#path_ = r\"OKPD2\\ro_bert_092_ner_rured_plus\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(path_)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_)\n",
    "\n",
    "nlp = pipeline(\"ner\", \n",
    "                model = model,\n",
    "                tokenizer = tokenizer,\n",
    "                ignore_labels=['O'], \n",
    "               aggregation_strategy=None)\n",
    "tokenizer.decode(tokenizer.encode('Привет мир'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[CLS] Привет мир [SEP]'"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "nlp(\"в МГУ поступили 100 человек\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORGANIZATION',\n",
       "  'score': 0.99938565,\n",
       "  'word': 'МГУ',\n",
       "  'start': 2,\n",
       "  'end': 5},\n",
       " {'entity_group': 'QUANTITY',\n",
       "  'score': 0.6999956,\n",
       "  'word': '100 человек',\n",
       "  'start': 16,\n",
       "  'end': 27}]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "nlp(' '.join(train_train['token']))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'entity': 'B-PROFESSION',\n",
       "  'score': 0.999322,\n",
       "  'index': 1,\n",
       "  'word': 'П',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.99919426,\n",
       "  'index': 2,\n",
       "  'word': '##ресс',\n",
       "  'start': 1,\n",
       "  'end': 5},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.9993947,\n",
       "  'index': 3,\n",
       "  'word': '-',\n",
       "  'start': 5,\n",
       "  'end': 6},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.99847245,\n",
       "  'index': 4,\n",
       "  'word': 'секретарь',\n",
       "  'start': 6,\n",
       "  'end': 15},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.9678861,\n",
       "  'index': 5,\n",
       "  'word': 'премьер',\n",
       "  'start': 16,\n",
       "  'end': 23},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.98625845,\n",
       "  'index': 6,\n",
       "  'word': '-',\n",
       "  'start': 23,\n",
       "  'end': 24},\n",
       " {'entity': 'B-PROFESSION',\n",
       "  'score': 0.9838654,\n",
       "  'index': 7,\n",
       "  'word': 'министра',\n",
       "  'start': 24,\n",
       "  'end': 32},\n",
       " {'entity': 'B-COUNTRY',\n",
       "  'score': 0.99791795,\n",
       "  'index': 8,\n",
       "  'word': 'России',\n",
       "  'start': 33,\n",
       "  'end': 39},\n",
       " {'entity': 'B-PERSON',\n",
       "  'score': 0.99979895,\n",
       "  'index': 9,\n",
       "  'word': 'Дмитрий',\n",
       "  'start': 40,\n",
       "  'end': 47},\n",
       " {'entity': 'I-PERSON',\n",
       "  'score': 0.9997193,\n",
       "  'index': 10,\n",
       "  'word': 'П',\n",
       "  'start': 48,\n",
       "  'end': 49},\n",
       " {'entity': 'I-PERSON',\n",
       "  'score': 0.99973243,\n",
       "  'index': 11,\n",
       "  'word': '##ес',\n",
       "  'start': 49,\n",
       "  'end': 51},\n",
       " {'entity': 'I-PERSON',\n",
       "  'score': 0.9997307,\n",
       "  'index': 12,\n",
       "  'word': '##ков',\n",
       "  'start': 51,\n",
       "  'end': 54},\n",
       " {'entity': 'B-ORGANIZATION',\n",
       "  'score': 0.99964505,\n",
       "  'index': 27,\n",
       "  'word': 'Р',\n",
       "  'start': 97,\n",
       "  'end': 98},\n",
       " {'entity': 'B-ORGANIZATION',\n",
       "  'score': 0.9996079,\n",
       "  'index': 28,\n",
       "  'word': '##ос',\n",
       "  'start': 98,\n",
       "  'end': 100},\n",
       " {'entity': 'B-ORGANIZATION',\n",
       "  'score': 0.99960315,\n",
       "  'index': 29,\n",
       "  'word': '##не',\n",
       "  'start': 100,\n",
       "  'end': 102},\n",
       " {'entity': 'B-ORGANIZATION',\n",
       "  'score': 0.99957734,\n",
       "  'index': 30,\n",
       "  'word': '##фти',\n",
       "  'start': 102,\n",
       "  'end': 105}]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#from RE_improved_baseline.model import REModel as model\n",
    "#import RE_improved_baseline.model as model\n",
    "from RE_improved_baseline.prepro import TACREDProcessor\n",
    "from RE_improved_baseline.train_tacred import predict\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "model_checkpoint = r'..\\OKPD2\\rubert_sber_ER_084_best'#\"cointegrated/rubert-tiny\"\n",
    "tokeniser__  = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace()\n",
    "args.max_seq_length = 512\n",
    "args.input_format = 'typed_entity_marker_punct'\n",
    "args.test_batch_size = 1\n",
    "args.device = 'cpu'\n",
    "\n",
    "processor = TACREDProcessor(tokenizer = tokeniser__,args = args)\n",
    "train_line_features = processor.read_line([train_train])"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_ner = torch.load(r'..\\OKPD2\\rubert_sber_ER_084_best\\model.pt', map_location=torch.device('cpu'))\n",
    "#model.eval()\n",
    "\n",
    "#args = argparse.Namespace()\n",
    "#args.test_batch_size = 1\n",
    "#args.device = 'cpu'\n",
    "\n",
    "predict(args=args, model=model_ner, features = train_line_features)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([0], [0.999417781829834])"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_train = {'id': 'brat/data/relations/Экономика/Все_6000/333340.ann/0',\n",
    " 'obj_end': 0,\n",
    " 'obj_start': 0,\n",
    " 'obj_type': 'PROFESSION',\n",
    " 'relation': 'WORKS_AS',\n",
    " 'stanford_ner': ['B-PROFESSION',\n",
    "  'B-PROFESSION',\n",
    "  'B-COUNTRY',\n",
    "  'B-PERSON',\n",
    "  'I-PERSON',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'B-ORGANIZATION',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O',\n",
    "  'O'],\n",
    " 'subj_end': 4,\n",
    " 'subj_start': 3,\n",
    " 'subj_type': 'PERSON',\n",
    " 'token': ['Пресс-секретарь',\n",
    "  'премьер-министра',\n",
    "  'России',\n",
    "  'Дмитрий',\n",
    "  'Песков',\n",
    "  'заявил',\n",
    "  ',',\n",
    "  'что',\n",
    "  'никаких',\n",
    "  'указаний',\n",
    "  'по',\n",
    "  'кадрам',\n",
    "  '\"',\n",
    "  'Роснефти',\n",
    "  '\"',\n",
    "  'не',\n",
    "  'было',\n",
    "  'и',\n",
    "  '\"',\n",
    "  'быть',\n",
    "  'не',\n",
    "  'могло',\n",
    "  '\"',\n",
    "  '.']}"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "foobar = [{'input_ids': [2,\n",
    "   7431,\n",
    "   2068,\n",
    "   16,\n",
    "   17865,\n",
    "   1614,\n",
    "   283,\n",
    "   22150,\n",
    "   11974,\n",
    "   603,\n",
    "   290,\n",
    "   9549,\n",
    "   19703,\n",
    "   11639,\n",
    "   603,\n",
    "   314,\n",
    "   4449,\n",
    "   29566,\n",
    "   341,\n",
    "   11011,\n",
    "   24509,\n",
    "   327,\n",
    "   23709,\n",
    "   2386,\n",
    "   29567,\n",
    "   1464,\n",
    "   29012,\n",
    "   12847,\n",
    "   16589,\n",
    "   29564,\n",
    "   3144,\n",
    "   559,\n",
    "   1478,\n",
    "   15660,\n",
    "   1134,\n",
    "   29565,\n",
    "   18,\n",
    "   2986,\n",
    "   30,\n",
    "   19,\n",
    "   19,\n",
    "   9160,\n",
    "   633,\n",
    "   18,\n",
    "   2643,\n",
    "   19,\n",
    "   3133,\n",
    "   19,\n",
    "   624,\n",
    "   19,\n",
    "   575,\n",
    "   19,\n",
    "   665,\n",
    "   19,\n",
    "   1347,\n",
    "   17633,\n",
    "   19,\n",
    "   3],\n",
    "  'labels': 1,\n",
    "  'os': 17,\n",
    "  'ss': 29}]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "subj_ners = ['B-PERSON', 'B-ORG']\n",
    "extra_obj_ners = ['B-LOCATION', 'B-NORP', 'B-GPE', 'B-DATE', 'B-TIME', 'B-CARDINAL','B-COUNTRY']\n",
    "misc_ners = ['B-EVENT', 'B-ORDINAL', 'B-QUANTITY', 'B-MONEY', 'B-PERCENT', 'B-LANGUAGE', 'B-LAW', 'B-FAC']\n",
    "\n",
    "all_ners = subj_ners + extra_obj_ners + misc_ners\n",
    "\n",
    "\n",
    "def is_pair_exist(tags, subj_ners, extra_obj_ners, misc_ners):\n",
    "    subj_entities = [x in subj_ners for x in tags]\n",
    "    obj_entities = [x in extra_obj_ners for x in tags]\n",
    "    misc_entities = [x in misc_ners for x in tags]\n",
    "    if any(obj_entities) and any(subj_entities):\n",
    "        return True\n",
    "    elif len([x for x in subj_entities if x]) > 1:\n",
    "        return True\n",
    "    elif any(subj_entities) and any(misc_entities):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "train_train_ = nlp(' '.join(train_train['token']))\n",
    "train_train_tags = [i['entity'] for i in train_train_]\n",
    "is_pair_exist(train_train_tags, subj_ners=subj_ners, extra_obj_ners=extra_obj_ners, misc_ners=misc_ners)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "new_train_of = [i for i in get_subj_and_obj_pairs(train_train_tags)][0]\n",
    "new_train_of"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((8, 11, 'B-PERSON'), (7, 7, 'B-COUNTRY'))"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "new_train = {'id':'0', \n",
    "            'obj_end': new_train_of[0][1], \n",
    "            'obj_start': new_train_of[0][0], \n",
    "            'obj_type': new_train_of[0][2], \n",
    "            'relation':'no_relation', \n",
    "            'stanford_ner':train_train_tags, \n",
    "            'subj_end': new_train_of[1][1], \n",
    "            'subj_start': new_train_of[1][0], \n",
    "            'subj_type': new_train_of[1][2], \n",
    "            'token':train_train['token']}"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_subj_and_obj_pairs(tags, commutative=True):\n",
    "    first_loop = [i for i, tag in enumerate(tags) if tag in subj_ners]\n",
    "    if commutative:\n",
    "        seen = set()\n",
    "    for subj_start in first_loop:\n",
    "        idx = 1\n",
    "        while subj_start + idx < len(tags) and tags[subj_start + idx].startswith('I-'):\n",
    "            idx += 1\n",
    "        subj_end = subj_start + idx - 1\n",
    "        second_loop = [i for i, tag in enumerate(tags) if tag in all_ners and i != subj_start]\n",
    "        for obj_start in second_loop:\n",
    "            idx = 1\n",
    "            while obj_start + idx < len(tags) and tags[obj_start + idx].startswith('I-'):\n",
    "                idx += 1\n",
    "            obj_end = obj_start + idx - 1\n",
    "            if commutative:\n",
    "                entities = tuple(sorted([subj_start, obj_start]))\n",
    "                if entities in seen:\n",
    "                    continue\n",
    "                else:\n",
    "                    seen.add(entities)\n",
    "\n",
    "            yield (subj_start, subj_end, tags[subj_start]), (obj_start, obj_end, tags[obj_start])"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "path_ = r'..\\OKPD2\\tiny_bert_087_ner_rured_plus'\n",
    "path_er = r'..\\OKPD2\\rubert_sber_ER_084_best'\n",
    "#path_ = r\"OKPD2\\ro_bert_092_ner_rured_plus\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(path_)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_)\n",
    "\n",
    "inferer_ner = pipeline(\"ner\", \n",
    "                model = model,\n",
    "                tokenizer = tokenizer,\n",
    "                ignore_labels=[], \n",
    "               aggregation_strategy=None)\n",
    "\n",
    "tokenizer.decode(tokenizer.encode('Привет мир'))\n",
    "\n",
    "model_er = torch.load(path_er+r'\\model.pt', map_location=torch.device('cpu'))\n",
    "tokenizer_er = AutoTokenizer.from_pretrained(path_er)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "' '.join(train_train['token'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Пресс-секретарь премьер-министра России Дмитрий Песков заявил , что никаких указаний по кадрам \" Роснефти \" не было и \" быть не могло \" .'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text = 'Пресс-секретарь премьер-министра России Дмитрий Песков заявил , что никаких указаний по кадрам \" Роснефти \" не было и \" быть не могло \" .'"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import argparse\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.max_seq_length = 512\n",
    "args.input_format = 'typed_entity_marker_punct'\n",
    "\n",
    "train_train_ = inferer_ner(text)\n",
    "train_train_tokens = [i['entity'] for i in train_train_]\n",
    "train_train_tags = [i['entity'] for i in train_train_]\n",
    "\n",
    "if is_pair_exist(train_train_tags, subj_ners=subj_ners, extra_obj_ners=extra_obj_ners, misc_ners=misc_ners):\n",
    "    new_train_of = [i for i in get_subj_and_obj_pairs(train_train_tags)][0]\n",
    "    new_train = {'id':'0', \n",
    "        'obj_end': new_train_of[0][1], \n",
    "        'obj_start': new_train_of[0][0], \n",
    "        'obj_type': new_train_of[0][2], \n",
    "        'relation':'no_relation', \n",
    "        'stanford_ner':train_train_tags, \n",
    "        'subj_end': new_train_of[1][1], \n",
    "        'subj_start': new_train_of[1][0], \n",
    "        'subj_type': new_train_of[1][2], \n",
    "        'token':train_train_tokens}\n",
    "\n",
    "\n",
    "    processor = TACREDProcessor(tokenizer = tokenizer_er,args = args)\n",
    "    train_line_features = processor.read_line([new_train])\n",
    "\n",
    "    args = argparse.Namespace()\n",
    "    args.test_batch_size = 1\n",
    "    args.device = 'cpu'\n",
    "    results = predict(args=args, model=model_er, features = train_line_features)\n",
    "    print({\n",
    "        'tag':results[0],\n",
    "        'prob':results[1]\n",
    "    }       )    \n",
    "else:\n",
    "    print({\n",
    "        'tag':'no_relation',\n",
    "        'prob':1.0\n",
    "    })"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tag': [0], 'prob': [0.9657171964645386]}\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "50f16b105d014d7a9acf15dfef919c5802ed9e89cab0aeb0d119ef42907784e0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}